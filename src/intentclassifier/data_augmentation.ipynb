{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models.wrappers.fasttext import FastText as FT_wrapper\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "m = Mystem()\n",
    "\n",
    "def mystem_analyze(str):\n",
    "    global m\n",
    "    try:\n",
    "        return m.analyze(str)\n",
    "    except BrokenPipeError as ex:\n",
    "        m = Mystem()\n",
    "        return mystem_analyze(str)\n",
    "    \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "DATASETS = Path('~/data/taskdialog').expanduser()\n",
    "MODELS = Path('~/data/taskdialog/models').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "with (DATASETS / 'youdo.txt').open() as f:\n",
    "    csvr = csv.reader(f, delimiter=',')\n",
    "    for row in csvr:\n",
    "        t = '\\n'.join(' '.join(wordpunct_tokenize(l)) for l in row[1].strip().splitlines() if l)\n",
    "        positives.append(t)\n",
    "\n",
    "# with (DATASETS / 'test.tsv').open() as f:\n",
    "#     c = csv.reader(f, delimiter='\\t')\n",
    "#     for label, text in c:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_imperative(word):\n",
    "    try:\n",
    "        p = [pm for pm in morph.parse(word) if 'INFN' in pm.tag][0]\n",
    "    except IndexError as ex:\n",
    "        return\n",
    "    try:\n",
    "        sing = p.inflect({'VERB', 'perf', 'impr', 'excl', 'plur'}).word\n",
    "        plur = p.inflect({'VERB', 'perf', 'impr', 'excl'}).word\n",
    "        return (sing, plur)\n",
    "    except AttributeError as ex:\n",
    "        return\n",
    "    \n",
    "assert to_imperative('Совершить') == ('совершите', 'соверши')\n",
    "    \n",
    "words_of_need = {'необходимо', 'нужно'}\n",
    "\n",
    "def get_imperative_variants(text):\n",
    "    try:\n",
    "        words = []\n",
    "        isinf = []\n",
    "        for tok in mystem_analyze(text.lower()):\n",
    "            if 'analysis' in tok:\n",
    "                if len(tok['analysis']) >= 1:\n",
    "                    gram = tok['analysis'][0]['gr']\n",
    "                    infinitive = 'инф' in gram and 'V' in gram\n",
    "                    w = tok['text']\n",
    "                    words.append(w)\n",
    "                    isinf.append(infinitive)\n",
    "        if max(isinf) == False:\n",
    "            return text,\n",
    "        if isinf[0]:\n",
    "            variants = []\n",
    "            for w, v in zip(words, isinf):\n",
    "                if v:\n",
    "                    imp = to_imperative(w)\n",
    "                    variants.append(imp or (w, w))\n",
    "                else:\n",
    "                    variants.append((w, w))\n",
    "            sing, plur = zip(*variants)\n",
    "            return text, ' '.join(sing), ' '.join(plur)\n",
    "        elif words_of_need.intersection(words):\n",
    "            prev_word = ''\n",
    "            variants = []\n",
    "            used_imperative = False\n",
    "            for w, v in zip(words, isinf):\n",
    "                if v and prev_word in words_of_need:\n",
    "                    imp = to_imperative(w)\n",
    "                    if imp:\n",
    "                        variants.pop()\n",
    "                        variants.append(imp)\n",
    "                        used_imperative = True\n",
    "                    else:\n",
    "                        variants.append((w, w))\n",
    "\n",
    "                else:\n",
    "                    variants.append((w, w))\n",
    "                prev_word = w\n",
    "\n",
    "            if used_imperative:\n",
    "                sing, plur = zip(*variants)\n",
    "                return text, ' '.join(sing), ' '.join(plur)\n",
    "    except ValueError as ex:\n",
    "        pass\n",
    "    return text,\n",
    "        \n",
    "assert get_imperative_variants('нужно сделать хорошо')[1] == 'сделайте хорошо'\n",
    "assert get_imperative_variants('повертеть попой')[2] == 'поверти попой'\n",
    "assert len(get_imperative_variants('хорошо сделать')) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-261d829d8879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mget_imperative_variants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-3139bc912c70>\u001b[0m in \u001b[0;36mget_imperative_variants\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misinf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_imperative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mvariants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-3139bc912c70>\u001b[0m in \u001b[0;36mto_imperative\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'VERB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'impr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'excl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plur'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mplur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'VERB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'impr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'excl'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.5/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36minflect\u001b[0;34m(self, required_grammemes)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired_grammemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired_grammemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.5/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m_inflect\u001b[0;34m(self, form, required_grammemes)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpossible_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mrequired_grammemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_rare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_grammemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             possible_results = [f for f in self.get_lexeme(form)\n\u001b[0m\u001b[1;32m    300\u001b[0m                                 if required_grammemes <= f[1].grammemes]\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.5/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpossible_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mrequired_grammemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_rare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_grammemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             possible_results = [f for f in self.get_lexeme(form)\n\u001b[0m\u001b[1;32m    300\u001b[0m                                 if required_grammemes <= f[1].grammemes]\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in positives:\n",
    "    try:\n",
    "        get_imperative_variants(p)\n",
    "    except ValueError as ex:\n",
    "        print(ex)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_imperative_variants('Есть ложь , есть большая ложь , есть статистика , а есть реклама .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='запостить', tag=OpencorporaTag('UNKN'), normal_form='запостить', score=1.0, methods_stack=((<UnknAnalyzer>, 'ить'), (<KnownPrefixAnalyzer>, 'пост'), (<KnownPrefixAnalyzer>, 'за')))]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('запостить')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
