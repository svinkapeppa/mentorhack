{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models.wrappers.fasttext import FastText as FT_wrapper\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "m = Mystem()\n",
    "\n",
    "\n",
    "def mystem_analyze(str):\n",
    "    global m\n",
    "    try:\n",
    "        return m.analyze(str)\n",
    "    except BrokenPipeError as ex:\n",
    "        m = Mystem()\n",
    "        return mystem_analyze(str)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "DATASETS = Path('~/data/taskdialog').expanduser()\n",
    "MODELS = Path('~/data/taskdialog/models').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_forum(f):\n",
    "    lines = []\n",
    "    for line in f:        \n",
    "        t = '\\n'.join(' '.join(wordpunct_tokenize(l)) for l in json.loads(line)['text'].strip().splitlines() if l.strip())\n",
    "        if t:\n",
    "            lines.append(t)\n",
    "    return lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238816\n"
     ]
    }
   ],
   "source": [
    "with (DATASETS / 'forummoskva.jsonl').open() as f:\n",
    "    texts = preprocess_forum(f)    \n",
    "    negatives.extend(texts)\n",
    "    print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15722973\n"
     ]
    }
   ],
   "source": [
    "with (DATASETS / 'dromru.jsonl').open() as f:\n",
    "    texts = preprocess_forum(f)    \n",
    "    negatives.extend(texts)\n",
    "    print(len(texts))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65593\n"
     ]
    }
   ],
   "source": [
    "with (DATASETS / 'vashdomru.jsonl').open() as f:\n",
    "    texts = preprocess_forum(f)    \n",
    "    negatives.extend(texts)  \n",
    "    print(len(texts))  # 300k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111866\n"
     ]
    }
   ],
   "source": [
    "with (DATASETS / 'antiwomenru.jsonl').open() as f:\n",
    "    texts = preprocess_forum(f)    \n",
    "    negatives.extend(texts)  \n",
    "    print(len(texts))  # 1.8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13025440\n"
     ]
    }
   ],
   "source": [
    "with (DATASETS / 'womenru.jsonl').open() as f:\n",
    "    texts = preprocess_forum(f)    \n",
    "    negatives.extend(texts)  \n",
    "    print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (DATASETS / 'dataset.tsv').open('w') as f:\n",
    "    csvw = csv.writer(f, delimiter='\\t')    \n",
    "    for line in negatives:\n",
    "        csvw.writerow([0, line])   \n",
    "\n",
    "del negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "with (DATASETS / 'youdo.txt').open() as f:\n",
    "    csvr = csv.reader(f, delimiter=',')\n",
    "    for row in csvr:\n",
    "        t = '\\n'.join(' '.join(wordpunct_tokenize(l)) for l in row[1].strip().splitlines() if l)\n",
    "        positives.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (DATASETS / 'dataset.tsv').open('a') as f:\n",
    "    csvw = csv.writer(f, delimiter='\\t')  \n",
    "    for line in positives:\n",
    "        csvw.writerow([1, line])      \n",
    "        \n",
    "del positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with (DATASETS / 'dataset.tsv').open() as f:\n",
    "    csvr = csv.reader(f, delimiter='\\t')\n",
    "    for label, text in csvr:\n",
    "        data.append((label, text))\n",
    "        \n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (DATASETS / 'dataset.txt').open('w') as f:\n",
    "#     for label, text in data:\n",
    "#         print(text, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_imperative(word):\n",
    "    try:\n",
    "        p = [pm for pm in morph.parse(word) if 'INFN' in pm.tag][0]\n",
    "    except IndexError as ex:\n",
    "        return\n",
    "    try:\n",
    "        sing = p.inflect({'VERB', 'perf', 'impr', 'excl', 'plur'}).word\n",
    "        plur = p.inflect({'VERB', 'perf', 'impr', 'excl'}).word\n",
    "        return (sing, plur)\n",
    "    except AttributeError as ex:\n",
    "        return\n",
    "    \n",
    "assert to_imperative('Совершить') == ('совершите', 'соверши')\n",
    "    \n",
    "words_of_need = {'необходимо', 'нужно'}\n",
    "\n",
    "def get_imperative_variants(text):\n",
    "    try:\n",
    "        words = []\n",
    "        isinf = []\n",
    "        for tok in mystem_analyze(text.lower()):\n",
    "            if 'analysis' in tok:\n",
    "                if len(tok['analysis']) >= 1:\n",
    "                    gram = tok['analysis'][0]['gr']\n",
    "                    infinitive = 'инф' in gram and 'V' in gram\n",
    "                    w = tok['text']\n",
    "                    words.append(w)\n",
    "                    isinf.append(infinitive)\n",
    "        if max(isinf) == False:\n",
    "            return text,\n",
    "        if isinf[0]:\n",
    "            variants = []\n",
    "            for w, v in zip(words, isinf):\n",
    "                if v:\n",
    "                    imp = to_imperative(w)\n",
    "                    variants.append(imp or (w, w))\n",
    "                else:\n",
    "                    variants.append((w, w))\n",
    "            sing, plur = zip(*variants)\n",
    "            return text, ' '.join(sing), ' '.join(plur)\n",
    "        elif words_of_need.intersection(words):\n",
    "            prev_word = ''\n",
    "            variants = []\n",
    "            used_imperative = False\n",
    "            for w, v in zip(words, isinf):\n",
    "                if v and prev_word in words_of_need:\n",
    "                    imp = to_imperative(w)\n",
    "                    if imp:\n",
    "                        variants.pop()\n",
    "                        variants.append(imp)\n",
    "                        used_imperative = True\n",
    "                    else:\n",
    "                        variants.append((w, w))\n",
    "\n",
    "                else:\n",
    "                    variants.append((w, w))\n",
    "                prev_word = w\n",
    "\n",
    "            if used_imperative:\n",
    "                sing, plur = zip(*variants)\n",
    "                return text, ' '.join(sing), ' '.join(plur)\n",
    "    except ValueError as ex:\n",
    "        pass\n",
    "    return text,\n",
    "        \n",
    "assert get_imperative_variants('нужно сделать хорошо')[1] == 'сделайте хорошо'\n",
    "assert get_imperative_variants('повертеть попой')[2] == 'поверти попой'\n",
    "assert len(get_imperative_variants('хорошо сделать')) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n",
      "520000\n",
      "540000\n",
      "560000\n",
      "580000\n",
      "600000\n",
      "620000\n",
      "640000\n",
      "660000\n",
      "680000\n",
      "700000\n",
      "720000\n",
      "740000\n",
      "760000\n",
      "780000\n",
      "800000\n",
      "820000\n",
      "840000\n",
      "860000\n",
      "880000\n",
      "900000\n",
      "920000\n",
      "940000\n",
      "960000\n",
      "980000\n",
      "1000000\n",
      "1020000\n",
      "1040000\n",
      "1060000\n",
      "1080000\n",
      "1100000\n",
      "1120000\n",
      "1140000\n",
      "1160000\n",
      "1180000\n",
      "1200000\n",
      "1220000\n",
      "1240000\n",
      "1260000\n",
      "1280000\n",
      "1300000\n",
      "1320000\n",
      "1340000\n",
      "1360000\n",
      "1380000\n",
      "1400000\n",
      "1420000\n",
      "1440000\n",
      "1460000\n",
      "1480000\n",
      "1500000\n",
      "1520000\n",
      "1540000\n",
      "1560000\n",
      "1580000\n",
      "1600000\n",
      "1620000\n",
      "1640000\n",
      "1660000\n",
      "1680000\n",
      "1700000\n",
      "1720000\n",
      "1740000\n",
      "1760000\n",
      "1780000\n",
      "1800000\n",
      "1820000\n"
     ]
    }
   ],
   "source": [
    "train_n = int(len(data) * 0.8)\n",
    "count = 0\n",
    "with (DATASETS / 'train2.tsv').open('w') as f:\n",
    "    csvw = csv.writer(f, delimiter='\\t')\n",
    "    for label, text in data[:train_n]:\n",
    "        count += 1\n",
    "        if count % 20000 == 0:\n",
    "            print(count)\n",
    "        if label == '1':\n",
    "            for augmented_text in get_imperative_variants(text):\n",
    "                csvw.writerow([label, augmented_text])\n",
    "        else:\n",
    "            csvw.writerow([label, augmented_text])\n",
    "\n",
    "# with (DATASETS / 'test.tsv').open('w') as f:\n",
    "#     csvw = csv.writer(f, delimiter='\\t')\n",
    "#     for label, text in data[train_n:]:\n",
    "#         csvw.writerow([label, text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Есть ложь , есть большая ложь , есть статистика , а есть реклама .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "with open('train.tsv') as f:\n",
    "    csvr = csv.reader(f, delimiter='\\t')\n",
    "    for label, text in csvr:\n",
    "        train_X.append(text)\n",
    "        train_y.append(int(label))\n",
    "        \n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_path = MODELS / 'tfidf'\n",
    "if tfidf_path.exists():\n",
    "    with tfidf_path.open('rb') as f:\n",
    "        tfidf = pickle.load(f)\n",
    "else:\n",
    "    tfidf = TfidfVectorizer()\n",
    "    train_X = tfidf.fit(train_X)\n",
    "    with tfidf_path.open('wb') as f:\n",
    "        pickle.dump(tfidf, f)\n",
    "\n",
    "train_X = tfidf.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 22.8 s, total: 3min 3s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m = LinearSVC()\n",
    "m.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', tfidf),\n",
    "                 ('classifier', m)])\n",
    "with (MODELS / 'classifier.pickle').open('wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'istask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0904704c1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsvr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'istask'"
     ]
    }
   ],
   "source": [
    "test_X = []\n",
    "test_y = []\n",
    "with (DATASETS / 'test.tsv').open() as f:\n",
    "    csvr = csv.reader(f, delimiter=',')\n",
    "    csv.read\n",
    "    for label, text in csvr:\n",
    "        test_X.append(text)\n",
    "        test_y.append(int(label))\n",
    "        \n",
    "test_y = np.array(test_y)\n",
    "test_X = tfidf.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy  ', (m.predict(test_X) == test_y).mean(), (m.predict(train_X) == train_y).mean(), sep='\\t')\n",
    "test_pos = test_y == 1\n",
    "train_pos = train_y == 1\n",
    "print('Pos Accuracy', (m.predict(train_X[train_pos]) == train_y[train_pos]).mean(), (m.predict(test_X[test_pos]) == test_y[test_pos]).mean(), sep='\\t')\n",
    "print('Neg Accuracy', (m.predict(train_X[~train_pos]) == train_y[~train_pos]).mean(), (m.predict(test_X[~test_pos]) == test_y[~test_pos]).mean(), sep='\\t')\n",
    "\n",
    "# 0.1\n",
    "\n",
    "\n",
    "# 1\n",
    "#   Accuracy\t0.9966766041670294\t0.9979463617801813\n",
    "# Pos Accuracy\t0.974006711709939\t0.9588633251535406\n",
    "# Neg Accuracy\t0.9993740346497515\t0.9989338185724046\n",
    "\n",
    "# 10\n",
    "#   Accuracy  \t0.9963909735848226\t0.9986286294275131\n",
    "# Pos Accuracy\t0.9831874787121008\t0.9592863243807536\n",
    "# Neg Accuracy\t0.9995494829858005\t0.9986058872573433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = FT_wrapper.train('/home/marat/fastText-0.1.0/fasttext', corpus_file=str(DATASETS / 'dataset.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.save('/home/marat/data/taskdialog/models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Юлус', 0.93408203125),\n",
       " ('=(,', 0.8703312277793884),\n",
       " ('=(\"', 0.869441032409668),\n",
       " (';(', 0.8526694178581238),\n",
       " (':(:(:(\"', 0.8471227288246155),\n",
       " (':(', 0.8459991216659546),\n",
       " ('дальше:(', 0.8446086049079895),\n",
       " (':(\"', 0.8394126296043396),\n",
       " ('((', 0.838272213935852),\n",
       " (':(:(:(', 0.8340241312980652)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.most_similar('=(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(len(data) * 0.8)\n",
    "\n",
    "with (DATASETS / 'train.csv').open('w') as f:\n",
    "    csvw = csv.writer(f)\n",
    "    csvw.writerow(['istask', 'request'])\n",
    "    for label, text in data[:train_n]:\n",
    "        csvw.writerow([label, text])\n",
    "\n",
    "with (DATASETS / 'test.csv').open('w') as f:\n",
    "    csvw = csv.writer(f)\n",
    "    csvw.writerow(['istask', 'request'])\n",
    "    for label, text in data[train_n:]:\n",
    "        csvw.writerow([label, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 13 01:23:16 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.12                 Driver Version: 390.12                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    42W / 300W |      2MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    42W / 300W |   2011MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    32W / 300W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    32W / 300W |      2MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    31W / 300W |      2MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    33W / 300W |      2MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    64W / 300W |   8667MiB / 16280MiB |     85%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0   145W / 300W |  15659MiB / 16280MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1      3972      C   python3                                     2001MiB |\n",
      "|    6      1509      C   python                                      8653MiB |\n",
      "|    7     34238      C   python                                     15645MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
